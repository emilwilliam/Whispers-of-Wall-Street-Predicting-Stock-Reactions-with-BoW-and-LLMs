{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LLM-Based Sentiment Analysis\n",
    "Here, I’m shifting gears to explore sentiment extraction using Large Language Models (LLMs). I’ll leverage OpenAI's models, and experiment with prompting of these models. This builds on the cleaned data from earlier, aiming to capture nuanced sentiment that BoW might miss. The goal remains the same: to evaluate how well these scores predict stock market reactions compared to other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Starting counter for run time\n",
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting the Earning Call data\n",
    "import sqlite3 as sql\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "\n",
    "### Getting the needed key\n",
    "%run 9-api_keys.ipynb\n",
    "\n",
    "# Create a connection to the SQLite database\n",
    "conn = sql.connect('data.db')\n",
    "ECs = pd.read_sql_query(\"SELECT * from ECs3\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ### Getting a sample of the data\n",
    "# # ECs = ECs.sample(10, random_state=42)\n",
    "\n",
    "# ### Getting just row 365, 1385 and 2634\n",
    "# row_numbers = [365, 1385, 2634]\n",
    "# ECs = ECs.iloc[row_numbers]\n",
    "\n",
    "# ### Resetting the index\n",
    "# ECs = ECs.reset_index(drop=True)\n",
    "\n",
    "# #Looking at the shape of the data\n",
    "# print(ECs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babbage-002\n",
      "chatgpt-4o-latest\n",
      "dall-e-2\n",
      "dall-e-3\n",
      "davinci-002\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4\n",
      "gpt-4-0125-preview\n",
      "gpt-4-0613\n",
      "gpt-4-1106-preview\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4-turbo-preview\n",
      "gpt-4.5-preview\n",
      "gpt-4.5-preview-2025-02-27\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-2024-08-06\n",
      "gpt-4o-2024-11-20\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-audio-preview-2024-10-01\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini-audio-preview\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-mini-search-preview\n",
      "gpt-4o-mini-search-preview-2025-03-11\n",
      "gpt-4o-mini-transcribe\n",
      "gpt-4o-mini-tts\n",
      "gpt-4o-realtime-preview\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "gpt-4o-search-preview\n",
      "gpt-4o-search-preview-2025-03-11\n",
      "gpt-4o-transcribe\n",
      "o1-mini\n",
      "o1-mini-2024-09-12\n",
      "o1-preview\n",
      "o1-preview-2024-09-12\n",
      "omni-moderation-2024-09-26\n",
      "omni-moderation-latest\n",
      "text-embedding-3-large\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "tts-1\n",
      "tts-1-1106\n",
      "tts-1-hd\n",
      "tts-1-hd-1106\n",
      "whisper-1\n"
     ]
    }
   ],
   "source": [
    "### Choice of model\n",
    "import requests\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {openai_key}\"\n",
    "}\n",
    "\n",
    "response = requests.get(\"https://api.openai.com/v1/models\", headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    models = response.json()[\"data\"]\n",
    "    for model in sorted(models, key=lambda m: m[\"id\"]):\n",
    "        print(model[\"id\"])\n",
    "else:\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configure OpenAI client (new style)\n",
    "import tiktoken\n",
    "def count_tokens(text, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"\n",
    "    Count the number of tokens in a given text using the specified OpenAI model.\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "client = openai.OpenAI(api_key=openai_key)\n",
    "def openai_llm(prompt, verbose=False, apply_template=True, temperature=0.7, max_tokens=150, model=\"gpt-3.5-turbo\", top_p=0.95):\n",
    "    \"\"\"\n",
    "    Send a prompt to OpenAI API (Chat or Completion) depending on the model.\n",
    "    \"\"\"\n",
    "    system_msg = \"You are a helpful analyst who evaluates sentiment in earnings call presentations and Q&As.\"\n",
    "    user_msg = prompt.strip()\n",
    "\n",
    "    # Handle Chat Models\n",
    "    if model.startswith(\"gpt-\"):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg}\n",
    "        ] if apply_template else [{\"role\": \"user\", \"content\": user_msg}]\n",
    "\n",
    "        if verbose:\n",
    "            print(\"=== Chat Prompt Messages ===\")\n",
    "            for msg in messages:\n",
    "                print(f\"{msg['role'].upper()}: {msg['content']}\")\n",
    "            print(\"============================\")\n",
    "        \n",
    "        if count_tokens(prompt + '' + system_msg) > 16000:\n",
    "            return np.nan\n",
    "        \n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                top_p=top_p\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "\n",
    "    # Handle Completion Models (e.g., text-davinci-003)\n",
    "    else:\n",
    "        full_prompt = f\"{system_msg}\\n\\n{user_msg}\" if apply_template else user_msg\n",
    "\n",
    "        if verbose:\n",
    "            print(\"=== Completion Prompt ===\")\n",
    "            print(full_prompt)\n",
    "            print(\"=========================\")\n",
    "\n",
    "        response = client.completions.create(\n",
    "            model=model,\n",
    "            prompt=full_prompt,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "            top_p=top_p\n",
    "        )\n",
    "        return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_earnings_sentiment(presentation_text, a_text, q_text, model=\"gpt-3.5-turbo\", temperature=0.0, max_tokens=150, what_to_analyze=\"P\"):\n",
    "    if what_to_analyze == \"P\":\n",
    "        # Analyze only presentations\n",
    "        prompt = f\"\"\"\n",
    "                Analyze the sentiment of the following earnings call presentation. Rate the sentiment on a scale from 1 (very negative) to 10 (very positive). Return only a single number as your response, with no additional text or explanation. Think step by step and consider the overall tone, language, and context of the text.\n",
    "\n",
    "                Text:\n",
    "                {presentation_text}\n",
    "                 \"\"\"\n",
    "        \n",
    "        response = openai_llm(prompt, model=model, temperature=temperature, max_tokens=max_tokens)\n",
    "        return response\n",
    "    elif what_to_analyze == \"A\":\n",
    "        # Analyze only answers\n",
    "        prompt = f\"\"\"\n",
    "                Analyze the sentiment of the following earnings call answers during the Q&A. Rate the sentiment on a scale from 1 (very negative) to 10 (very positive). Return only a single number as your response, with no additional text or explanation. Think step by step and consider the overall tone, language, and context of the text.\n",
    "\n",
    "                Text:\n",
    "                {a_text}\n",
    "                 \"\"\"\n",
    "        response = openai_llm(prompt, model=model, temperature=temperature, max_tokens=max_tokens)\n",
    "        return response\n",
    "    elif what_to_analyze == \"Q\":\n",
    "        # Analyze only answers\n",
    "        prompt = f\"\"\"\n",
    "                Analyze the sentiment of the following earnings call questions during the Q&A. Rate the sentiment on a scale from 1 (very negative) to 10 (very positive). Return only a single number as your response, with no additional text or explanation. Think step by step and consider the overall tone, language, and context of the text.\n",
    "\n",
    "                Text:\n",
    "                {q_text}\n",
    "                 \"\"\"\n",
    "        response = openai_llm(prompt, model=model, temperature=temperature, max_tokens=max_tokens)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_earnings_sentiment_with_EPS(presentation_text, a_text, q_text, earning_suprise, model=\"gpt-3.5-turbo\", temperature=0.0, max_tokens=150, what_to_analyze=\"P\"):\n",
    "    if what_to_analyze == \"P\":\n",
    "        # Analyze only presentations\n",
    "        prompt = f\"\"\"\n",
    "                Analyze the sentiment of the following earnings call presentation. We already know that the scalled earnings suprise (Actual EPS - Expected EPS) is {earning_suprise}. Rate the sentiment on a scale from 1 (very negative) to 10 (very positive). Return only a single number as your response, with no additional text or explanation. Think step by step and consider the overall tone, language, and context of the text.\n",
    "\n",
    "                Text:\n",
    "                {presentation_text}\n",
    "                 \"\"\"\n",
    "        \n",
    "        response = openai_llm(prompt, model=model, temperature=temperature, max_tokens=max_tokens)\n",
    "        return response\n",
    "    elif what_to_analyze == \"A\":\n",
    "        # Analyze only answers\n",
    "        prompt = f\"\"\"\n",
    "                Analyze the sentiment of the following earnings call answers during the Q&A. We already know that the scalled earnings suprise (Actual EPS - Expected EPS) is {earning_suprise}. Rate the sentiment on a scale from 1 (very negative) to 10 (very positive). Return only a single number as your response, with no additional text or explanation. Think step by step and consider the overall tone, language, and context of the text.\n",
    "\n",
    "                Text:\n",
    "                {a_text}\n",
    "                 \"\"\"\n",
    "        response = openai_llm(prompt, model=model, temperature=temperature, max_tokens=max_tokens)\n",
    "        return response\n",
    "    elif what_to_analyze == \"Q\":\n",
    "        # Analyze only answers\n",
    "        prompt = f\"\"\"\n",
    "                Analyze the sentiment of the following earnings call questions during the Q&A. We already know that the scalled earnings suprise (Actual EPS - Expected EPS) is {earning_suprise}. Rate the sentiment on a scale from 1 (very negative) to 10 (very positive). Return only a single number as your response, with no additional text or explanation. Think step by step and consider the overall tone, language, and context of the text.\n",
    "\n",
    "                Text:\n",
    "                {q_text}\n",
    "                 \"\"\"\n",
    "        response = openai_llm(prompt, model=model, temperature=temperature, max_tokens=max_tokens)\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def anonymize(text):\n",
    "    # Step 1: Replace company names\n",
    "    text = re.sub(r\"([A-Z][A-Za-z0-9]*(?:\\s+[A-Z][A-Za-z0-9]*)*)\\s+(Earnings|Conference Call|Inc\\.|Corp\\.|Corporation)\", r\"[Company] \\2\", text)\n",
    "    text = text.replace(\"[Company] Earnings\", \"[Company] [Quarter] Earnings\")\n",
    "\n",
    "    # Step 2: Replace executive names dynamically\n",
    "    exec_pattern = r\"(?:Mr\\.|Ms\\.|Mrs\\.|Dr\\.|\\bturn\\s+the\\s+conference\\s+over\\s+to\\b|\\bon\\s+the\\s+call\\s+today\\s+are\\b)\\s+([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)+)(?:,|\\s+(Executive\\s+Chairman|Chief\\s+Executive\\s+Officer|Chief\\s+Financial\\s+Officer|Vice\\s+President|President|CEO|CFO|COO))\"\n",
    "    exec_counter = 1\n",
    "    exec_replacements = {}\n",
    "    for match in re.finditer(exec_pattern, text, re.IGNORECASE):\n",
    "        full_name = match.group(1)\n",
    "        if full_name not in exec_replacements:\n",
    "            exec_replacements[full_name] = f\"[Executive {exec_counter}]\"\n",
    "            exec_counter += 1\n",
    "    for name, placeholder in exec_replacements.items():\n",
    "        text = text.replace(name, placeholder)\n",
    "\n",
    "    # Step 3: Replace brands, programs, films (avoiding prior replacements)\n",
    "    # Simplified pattern: Capitalized phrases followed by context words\n",
    "    brand_pattern = r\"\\b([A-Z][A-Za-z0-9]*(?:\\s+[A-Z][A-Za-z0-9]*)*)(?:\\s+(Network|Series|Film|Channel|Studio|Live))\"\n",
    "    brand_counter = 1\n",
    "    program_counter = 1\n",
    "    film_counter = 1\n",
    "    brand_replacements = {}\n",
    "    for match in re.finditer(brand_pattern, text):\n",
    "        entity = match.group(1)\n",
    "        context = match.group(2).lower()\n",
    "        # Skip if already replaced as Company or Executive\n",
    "        if not re.search(r\"\\[Company\\]|\\[Executive \\d+\\]\", entity) and entity not in brand_replacements:\n",
    "            if \"series\" in context or \"live\" in context:\n",
    "                brand_replacements[entity] = f\"[Program {program_counter}]\"\n",
    "                program_counter += 1\n",
    "            elif \"film\" in context or \"studio\" in context:\n",
    "                brand_replacements[entity] = f\"[Film {film_counter}]\"\n",
    "                film_counter += 1\n",
    "            else:\n",
    "                brand_replacements[entity] = f\"[Brand {brand_counter}]\"\n",
    "                brand_counter += 1\n",
    "    for entity, placeholder in brand_replacements.items():\n",
    "        text = text.replace(entity, placeholder)\n",
    "\n",
    "    # Step 4: Replace platforms\n",
    "    platform_pattern = r\"(?:on|with|to|via)\\s+([A-Z][A-Za-z0-9]*(?:\\s+[A-Z][A-Za-z0-9]*)*)(?:\\s+(platform|service|streaming|TV|mobile))\"\n",
    "    platform_counter = 1\n",
    "    platform_replacements = {}\n",
    "    for match in re.finditer(platform_pattern, text, re.IGNORECASE):\n",
    "        platform = match.group(1)\n",
    "        if platform not in platform_replacements and not re.search(r\"\\[Company\\]|\\[Executive \\d+\\]|\\[Brand \\d+\\]|\\[Program \\d+\\]|\\[Film \\d+\\]\", platform):\n",
    "            platform_replacements[platform] = f\"[Platform {platform_counter}]\"\n",
    "            platform_counter += 1\n",
    "    for platform, placeholder in platform_replacements.items():\n",
    "        text = text.replace(platform, placeholder)\n",
    "\n",
    "    # Step 5: Replace dates and quarters\n",
    "    text = re.sub(r\"(First|Second|Third|Fourth)\\s+Quarter\\s+\\d{4}\", \"[Quarter]\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"\\b(January|February|March|April|May|June|July|August|September|October|November|December)\\b\", \"[Month]\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Clean up extra whitespace\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Unfortunately, the API key expired while running the code below, so this section has been shortened.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process each row\n",
    "def process_row(row, what_to_analyze=\"P\"):\n",
    "    pres = anonymize(row['P'])\n",
    "    ans = anonymize(row['A'])\n",
    "    quest = anonymize(row['Q'])\n",
    "    surpdec = row['SurpDec']\n",
    "    \n",
    "    openai_score = analyze_earnings_sentiment(\n",
    "        presentation_text=pres, \n",
    "        a_text=ans, \n",
    "        q_text=quest,\n",
    "        model=\"gpt-3.5-turbo\", \n",
    "        temperature=0, \n",
    "        max_tokens=150,\n",
    "        what_to_analyze=what_to_analyze\n",
    "    )\n",
    "    \n",
    "    # openai_eps_score = analyze_earnings_sentiment_with_EPS(\n",
    "    #     presentation_text=pres, \n",
    "    #     earning_suprise=surpdec, \n",
    "    #     a_text=ans, \n",
    "    #     q_text=quest,\n",
    "    #     model=\"gpt-3.5-turbo\", \n",
    "    #     temperature=0, \n",
    "    #     max_tokens=150,\n",
    "    #     what_to_analyze=what_to_analyze\n",
    "    # )\n",
    "    \n",
    "    return pd.Series([openai_score])\n",
    "\n",
    "# Apply the function to the dataset\n",
    "ECs[['openai_P']] = ECs.apply(process_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to process each row\n",
    "# def process_row(row, what_to_analyze=\"A\"):\n",
    "#     pres = anonymize(row['P'])\n",
    "#     ans = anonymize(row['A'])\n",
    "#     quest = anonymize(row['Q'])\n",
    "#     surpdec = row['SurpDec']\n",
    "    \n",
    "#     openai_score = analyze_earnings_sentiment(\n",
    "#         presentation_text=pres, \n",
    "#         a_text=ans, \n",
    "#         q_text=quest,\n",
    "#         model=\"gpt-3.5-turbo\", \n",
    "#         temperature=0, \n",
    "#         max_tokens=150,\n",
    "#         what_to_analyze=what_to_analyze\n",
    "#     )\n",
    "    \n",
    "#     openai_eps_score = analyze_earnings_sentiment_with_EPS(\n",
    "#         presentation_text=pres, \n",
    "#         earning_suprise=surpdec, \n",
    "#         a_text=ans, \n",
    "#         q_text=quest,\n",
    "#         model=\"gpt-3.5-turbo\", \n",
    "#         temperature=0, \n",
    "#         max_tokens=150,\n",
    "#         what_to_analyze=what_to_analyze\n",
    "#     )\n",
    "    \n",
    "#     return pd.Series([openai_score, openai_eps_score])\n",
    "\n",
    "# # Apply the function to the dataset\n",
    "# ECs[['openai_A', 'openai_eps_A']] = ECs.apply(process_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to process each row\n",
    "# def process_row(row, what_to_analyze=\"Q\"):\n",
    "#     pres = anonymize(row['P'])\n",
    "#     ans = anonymize(row['A'])\n",
    "#     quest = anonymize(row['Q'])\n",
    "#     surpdec = row['SurpDec']\n",
    "    \n",
    "#     openai_score = analyze_earnings_sentiment(\n",
    "#         presentation_text=pres, \n",
    "#         a_text=ans, \n",
    "#         q_text=quest,\n",
    "#         model=\"gpt-3.5-turbo\", \n",
    "#         temperature=0, \n",
    "#         max_tokens=150,\n",
    "#         what_to_analyze=what_to_analyze\n",
    "#     )\n",
    "    \n",
    "#     openai_eps_score = analyze_earnings_sentiment_with_EPS(\n",
    "#         presentation_text=pres, \n",
    "#         earning_suprise=surpdec, \n",
    "#         a_text=ans, \n",
    "#         q_text=quest,\n",
    "#         model=\"gpt-3.5-turbo\", \n",
    "#         temperature=0, \n",
    "#         max_tokens=150,\n",
    "#         what_to_analyze=what_to_analyze\n",
    "#     )\n",
    "    \n",
    "#     return pd.Series([openai_score, openai_eps_score])\n",
    "\n",
    "# # Apply the function to the dataset\n",
    "# ECs[['openai_Q', 'openai_eps_Q']] = ECs.apply(process_row, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving just the openai_P data\n",
    "openai = ECs['openai_P']\n",
    "\n",
    "### Saving the data\n",
    "conn = sql.connect('data.db')\n",
    "ECs.to_sql('ECs4', conn, if_exists='replace', index=False)\n",
    "openai.to_sql('openai', conn, if_exists='replace', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 3565.87 seconds\n"
     ]
    }
   ],
   "source": [
    "### Stopping the timer\n",
    "end_time = time.time()\n",
    "print(f\"Execution time: {end_time - start_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
